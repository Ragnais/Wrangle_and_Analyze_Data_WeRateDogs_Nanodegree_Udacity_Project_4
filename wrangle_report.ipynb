{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA WRANGLING REPORT\n",
    "\n",
    "\n",
    "#### Aisulu Raganina\n",
    "\n",
    "\n",
    "#### Udacity Project: Wrangle and analyze Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Introduction\n",
    "\n",
    "The project shows proficiency in data wrangling and analyses and includes several steps:\n",
    "\n",
    "1.\tGathering;\n",
    "\n",
    "2.\tAssessing;\n",
    "\n",
    "3.\tCleaning;\n",
    "\n",
    "4.\tStoring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### 1.Gathering \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The data was gathered from 3 sources and stored in separate files:\n",
    "\n",
    "1.\tdf_tw_archive  was read as CSV file from twitter_archive_enhanced.csv;\n",
    "\n",
    "2.\timage_predictions was downloaded programmatically;\n",
    "\n",
    "3.\ttweet_info  JSON data was downloaded by querying the Twitter API using the Tweepy library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 2.Assessing \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Each dataframe was assessed visually using several pandas functions: head(), tail(), info(), unique(), value_counts(), count(), describe(). The possible duplicates and missing values were checked. The main objectives were to look for the quality and tidiness issues and to understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality and tidiness issues were inspected for further cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quality Issues\t\n",
    "\n",
    "\n",
    "df_tw_archive\t\n",
    "\n",
    "1. Incorrect data type for timestamp and retweeted_status_timestamp \n",
    "\n",
    "2. Invalid values: 'O' to 'O'Malley'; 'Al' to 'Al Cabone'; 'my' to 'Zoey'\t\n",
    "\n",
    "3. We want to have only original ratings (no retweets) that have images \t\n",
    "\n",
    "4. Column „Name“ includes invalid names \"a\", \"an\",  \"the\" etc\n",
    "\n",
    "5. There are 'None' missing values in „Name“  \t\n",
    "\n",
    "6. The columns rating_denominator and rating_numerator have invalid values\n",
    "\n",
    "\n",
    "image_predictions\t\n",
    "\n",
    "7. According to the p1-dog, p2-dog and p3-dog together, there are 324 rows with no dog on the picture\t\n",
    "\n",
    "8. The p1,p2 and p3 include Uppercase and Lowercase for the first letter\t\n",
    "\n",
    "\n",
    "tweet_info\t\n",
    "\n",
    "9. The column  „id“ should be changed to „tweet_id“ for joining DFs\t\n",
    "\n",
    "10. Duplicates were found\t\n",
    "    \n",
    "    \n",
    "##### Tidiness Issues\n",
    "\n",
    "\n",
    "df_tw_archive\t\n",
    "\n",
    "1.  The columns doggo, floofer, pupper, puppo should be in one column „Stage“\n",
    "\n",
    "\n",
    "\n",
    "tweet_info\n",
    "\n",
    "2. Join tweet_info with df_tw_archive and image_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the cleaning of the data, additional assessment was necessary because after resolving the tidiness issue with column „Stage“ for doggo, floofer, pupper, puppo, the invalid values  were identified: doggopupper- 10; doggofloofer-1; doggopuppo-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.Cleaning \n",
    "\n",
    "\n",
    "For cleaning purposes, the copies of original dataframes were created:\n",
    "\n",
    "1.\tdf_tw_archive_clean = df_tw_archive.copy()\n",
    "\n",
    "2.\timage_predictions_clean = image_predictions.copy()\n",
    "\n",
    "3.\ttweet_info_clean = tweet_info.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_tw_archive_clean\t\n",
    "\n",
    "1. Changed to datetime by using pd.to_datetime\n",
    "\n",
    "2. Replaced 'O' to 'O'Malley'; 'Al' to 'Al Cabone'; 'my' to 'Zoey'\n",
    "\n",
    "3. Removed 'retweeted_status_id' which were not null and removed columns 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'\n",
    "4. As most of the invalid values for names are  starting from the lowercase letter and the text includes the real names, the names were retrieved and replaced to the column „Name“ from „Text“ column with the information after the key words:  'named' and 'name is' . \n",
    "\n",
    "5. Additionally, 'None' missing values were changed to NaN in column „Name“ \n",
    "\n",
    "6. The denominator should be 10. In the column „Text“ we can find the correct rating based on 10. Therefore, the denominator and numerator were changed where the text gives the correct rating\n",
    "\n",
    "image_predictions_clean\n",
    "\n",
    "7. 324 rows were dropped using drop_duplicates()\n",
    "\n",
    "8. The first letter of dog breeds‘ names replaced  with uppercase in columns  p1,p2 and p3\n",
    "\n",
    "9. The new column „Stage“ was created in order to store the variables doggo, floofer, pupper, puppo\n",
    "\n",
    "10. The invalid values for doggopupper, doggofloofer and doggopuppo were additionally assessed\n",
    "\n",
    "11. There were some NaN in column „Name“ for invalid values doggopupper. Hence, it was impossible to detect the correct dog stage. Thus, the invalid values of doggopupper  where column „Name“ included NaN were changed to np.nan. Other incorrect values had the correct dog stage in the text and were renamed correspondingly\n",
    "\n",
    "tweet_info_clean\t\n",
    "\n",
    "12. The column „id“ was renamed to „tweet_id“ using function rename()\n",
    "\n",
    "13. The duplicates were dropped using drop_duplicates()\n",
    "\n",
    "14. All three tables were joined using pd.merge()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Storing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the new cleaned and merged dataframe was stored as 'twitter_archive_master.csv'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
